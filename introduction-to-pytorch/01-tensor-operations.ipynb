{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# An Introduction to PyTorch functions\n",
    "\n",
    "### What is Pytorch?\n",
    "PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab.It is free and open-source software released under the Modified BSD license.\n",
    "\n",
    "So in this notebook we will be going through the five basic pytorch functions that comes in handy when dealing with any deep learning project.\n",
    "Before that lets first understand what a Tensor is and how to create it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### Tensor\n",
    "A torch.Tensor is a multi-dimensional matrix containing elements of a single data type and torch.Tensor is an alias for the default tensor type (torch.FloatTensor).\n",
    "\n",
    "The torch package contains data structures for multi-dimensional tensors and mathematical operations over these are defined. Additionally, it provides many utilities for efficient serializing of Tensors and arbitrary types, and other useful utilities.\n",
    "We can use import the torch module and start using the functions provided by it.\n",
    "\n",
    "Tensor can be created as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Once the torch library is imported we can create tensors and start using its functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above example we have created 2D matrix. We can create tensors of other dimensions as well.\n",
    "\n",
    "So now as we have basic understanding of what tensor is,we will go through following five basic functions that comes in handy when we are dealing with tensors. We will see some of the working examples and also when it breaks.\n",
    "\n",
    "- torch.mm(mat1,mat2)\n",
    "- torch.exp(m1)\n",
    "- torch.numpy() and torch.from_numpy()\n",
    "- torch.dot()\n",
    "- torch.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 1. torch.mm(input, mat2, out=None) → Tensor\n",
    "\n",
    "Whenever we are dealing with Deep Learning projects, we often want to do Matrix multiplication and instead of writing the function ourselves pytorch already comes with torch.mm function which can be used. This function peforms a matrix multiplication of two matrices.\n",
    "If you remember from your school days about the matrix multiplication, If matrix m1 is (n * m) and matrix m2 is (m * p) dimension then resultant matrix is of (n * p) dimension. \n",
    "\n",
    "### Parameters:\n",
    "* input (Tensor) – the first matrix to be multiplied\n",
    "* mat2 (Tensor) – the second matrix to be multiplied\n",
    "* out (Tensor, optional) – the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9865,  0.0648],\n",
       "        [ 0.0793, -0.1125]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "mat1 = torch.randn(2, 3)\n",
    "mat2 = torch.randn(3, 2)\n",
    "torch.mm(mat1, mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    " So,As you can see from above example matrix1 is of dimension 2X3 and matrix2 is of dimension 3X2 and the resultant matrix is of dimension 2X2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.9414,  4.8710,  3.5058,  2.3394],\n",
       "        [-4.6168, -3.4696,  0.1253, -3.0327],\n",
       "        [-1.8363, -0.6990,  2.5023,  0.8781],\n",
       "        [-0.3595, -0.8358,  1.9683, -1.9978]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat3 = torch.randn(4, 5)\n",
    "mat4 = torch.randn(5, 4)\n",
    "torch.mm(mat3, mat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [4 x 3], m2: [5 x 4] at /opt/conda/conda-bld/pytorch_1587428190859/work/aten/src/TH/generic/THTensorMath.cpp:41",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b871e027209e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmat5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmat6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [4 x 3], m2: [5 x 4] at /opt/conda/conda-bld/pytorch_1587428190859/work/aten/src/TH/generic/THTensorMath.cpp:41"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (to illustrate when it breaks)\n",
    "mat5 = torch.randn(4, 3)\n",
    "mat6 = torch.randn(5, 4)\n",
    "torch.mm(mat5, mat6)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above example, as matrix multiplication dimension rule doesnt satisfy it throws Runtime Errror.\n",
    "\n",
    "So next time whenever you want to use matrix multiplication, make use of this function which is very handy."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 2. torch.exp(input, out=None) → Tensor\n",
    "\n",
    "Normally when we are dealing with calculating the loss of our model we want to calculate the exponential, then torch.exp() is helpful.\n",
    "This function returns new tensor with the exponential of the elements of the input tensor.\n",
    "### Parameters:\n",
    "* input (Tensor) – the input tensor.\n",
    "* out (Tensor, optional) – the output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1131,  0.5741,  1.0501, -1.0276],\n",
       "        [ 1.1006, -0.0143,  0.3346, -0.5065],\n",
       "        [ 2.8669, -0.1604, -0.1741,  1.2063]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "exp1 = torch.randn(3,4)\n",
    "exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1198,  1.7755,  2.8581,  0.3579],\n",
       "        [ 3.0059,  0.9858,  1.3974,  0.6026],\n",
       "        [17.5822,  0.8518,  0.8402,  3.3411]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(exp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above example the exponential function is called for the exp1 matrix which returns the exponential of all elements of tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2441, 1.4585, 3.4836, 1.8864],\n",
       "        [0.9397, 0.5054, 2.8767, 1.2165],\n",
       "        [1.0114, 0.2242, 1.0229, 0.8814]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "exp1 = torch.randn(3,4)\n",
    "torch.exp(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exp() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f1745bf97d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - doesn't works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: exp() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# Example 3 - doesn't works\n",
    "t = torch.exp(1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "So next time whenever you want to calculate the exponential of matrix, make use of this function which is very handy."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 3.torch.numpy() → ndarray & torch.from_numpy(ndarray) → Tensor\n",
    "\n",
    "Normally when we are dealing with deep learning and using numpy we may want to inter change the tensor to numpy array and viceversa. torch.numpy() is handy function which tensor as numpy array. The tensor and numpy share the same underlying storage. So any changes done to tensor will be reflected in numpy array and viceversa.And other function torch.from_numpy() creates a new tensor from numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06350555, -1.2775818 ],\n",
       "       [-0.8546675 ,  0.07112499]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "tensor1 = torch.randn(2,2)\n",
    "nparray1 = tensor1.numpy()\n",
    "nparray1"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above example tensor1 is of type tensor and using the function numpy we can get the relevant numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0635, -1.2776],\n",
       "        [-0.8547,  0.0711]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "tensor2 = torch.from_numpy(nparray1)\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above example we created a tensor back from numpy array.\n",
    "So these two functions will be very useful when we are dealing with the numpy and tensor in our project and if we want to convert from one type to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cacfc73993ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Example 3 - breaking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtensor3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtensor3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
     ]
    }
   ],
   "source": [
    "#Example 3 - breaking\n",
    "tensor3 = torch.from_numpy([1,2])\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above example, if we try to pass other than numpy array it will fail. So make sure you have numpy array which can passed.\n",
    "\n",
    "So from the functions torch.numpy() and torch.from_numpy() we see that its easier to convert from numpy array to tensor and viceversa.\n",
    "Certainly these will be very handy when we are dealing with deep learning projects"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 4. torch.dot(input, tensor) → Tensor\n",
    "\n",
    "Dot product is common functionality that we require whenever we are dealing with deep learning projects. For this, pytorch makes easier to compute by providing the torch.dot() function which returns the dot product of two input tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(68)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "torch.dot(torch.tensor([4, 5]), torch.tensor([7, 8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "In the above examples,we can see the dot product of the two input tensors returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements, but got 3 and 2 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6e3a3d774b23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - Doesnt works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [3] and src [2] to have the same number of elements, but got 3 and 2 elements respectively"
     ]
    }
   ],
   "source": [
    "# Example 3 - Doesnt works\n",
    "torch.dot(torch.tensor([4, 5, 6]), torch.tensor([7, 8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "The above fails to run and gives exception as the two input tensors should have the same dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 5. torch.flatten(input, start_dim=0, end_dim=-1) → Tensor[](http://)\n",
    "\n",
    "When we are dealing with images in deep learning projects, sometimes we need to flattern the dimension of matrix to single vector, in those situations we can use the tensor.flatten() function. SO this function flattens a contiguous range of dims in a tensor.\n",
    "\n",
    "Parameters:\n",
    "* input (Tensor) – the input tensor.\n",
    "* start_dim (int) – the first dim to flatten\n",
    "* end_dim (int) – the last dim to flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - working\n",
    "t = torch.tensor([[1, 2],\n",
    "                  [3, 4],\n",
    "                  [5, 6]])\n",
    "torch.flatten(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "As you can see from the above example, input tensor is of dimension is of 2*3 dimension and flatten function returns flattens and returns 1D dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - working\n",
    "torch.flatten(t, end_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Explanation about example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e6c50ee4db52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example 3 - breaking (when we give invalid dimensions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking (when we give invalid dimensions)\n",
    "torch.flatten(t, start_dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "So from the above examples it's clear that this function comes in handy whenever we want to return flat structure of our tensor and perform operations on it."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook we came across 5 important pytorch functions to work with tensors. Along with when the functions can be used, we should keep an eye on the conditions under which they break.\n",
    "Apart from this pytorch documentation is great resource and we should constantly check those keep ourselves updated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Reference Links\n",
    "You can go through the official Pytorch documentation which is a great resource of such methods with good examples.\n",
    "* Official documentation for `torch.Tensor`: https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pip install jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
